#!/usr/bin/env python3
import os
import boto3
import tarfile
import shutil
from datetime import datetime, timedelta

# ========== é…ç½® ==========
S3_BUCKET = "aws-jp-prod-wazuh-s3"
S3_PREFIX = "wazuh-backups/var/ossec"
LOG_BASE = "/var/ossec/logs"
TMP_BASE = "/tmp"

# æ—¥å¿—å­ç›®å½•
LOG_DIRS = [
    "alerts",
    "api",
    "archives",
    "cluster",
    "firewall",
    "wazuh",
]

# éœ€è¦æ‰“åŒ…ä¸Šä¼ çš„ç›®å½•
PACKAGE_DIRS = [
    "/var/ossec/etc",
    "/var/ossec/ruleset",
    "/var/ossec/api",
]

# åˆå§‹åŒ– S3 å®¢æˆ·ç«¯
s3 = boto3.client("s3")

# ========== è·å–å‰ä¸€å¤©æ—¥æœŸ ==========
def get_yesterday():
    d = datetime.now() - timedelta(days=1)
    return {
        "year": d.strftime("%Y"),
        "month": d.strftime("%b"),
        "day": d.strftime("%d"),
    }

# ========== ä¸Šä¼ æ–‡ä»¶ ==========
def upload_file(local_path, s3_key):
    try:
        s3.upload_file(local_path, S3_BUCKET, s3_key)
        print(f"âœ… ä¸Šä¼  {local_path} â†’ s3://{S3_BUCKET}/{s3_key}")
    except Exception as e:
        print(f"âŒ ä¸Šä¼ å¤±è´¥ {local_path} â†’ {s3_key} : {e}")

# ========== åˆ é™¤ä¸´æ—¶æ–‡ä»¶ ==========
def clean_up(path):
    if os.path.exists(path):
        if os.path.isfile(path):
            os.remove(path)
            print(f"ğŸ—‘ï¸ åˆ é™¤ä¸´æ—¶æ–‡ä»¶ {path}")
        elif os.path.isdir(path):
            shutil.rmtree(path)
            print(f"ğŸ—‘ï¸ åˆ é™¤ä¸´æ—¶ç›®å½• {path}")

# ========== å¤‡ä»½æ—¥å¿—ï¼ˆåªä¸Šä¼ å‰ä¸€å¤©ï¼‰ ==========
def backup_logs():
    date = get_yesterday()
    year, month, day = date["year"], date["month"], date["day"]

    for log_dir in LOG_DIRS:
        local_dir = os.path.join(LOG_BASE, log_dir)
        if not os.path.isdir(local_dir):
            print(f"âš ï¸ è·³è¿‡ä¸å­˜åœ¨ç›®å½•: {local_dir}")
            continue

        print(f"\nğŸ“ å¤„ç†ç›®å½•: {local_dir}")

        for root, _, files in os.walk(local_dir):
            # åˆ¤æ–­è·¯å¾„ä¸­æ˜¯å¦åŒ…å«å‰ä¸€å¤©å¹´æœˆ
            if f"{year}" not in root or f"{month}" not in root:
                continue

            for filename in files:
                # æ–‡ä»¶åä¸­å¿…é¡»åŒ…å«å‰ä¸€å¤©æ—¥
                if f"-{day}." not in filename and f"-{day}-" not in filename:
                    continue

                local_file = os.path.join(root, filename)
                rel_path = os.path.relpath(local_file, "/var/ossec")
                s3_key = f"{S3_PREFIX}/{rel_path}"
                upload_file(local_file, s3_key)

# ========== é€šç”¨æ‰“åŒ…ä¸Šä¼ å‡½æ•° ==========
def backup_dir(dir_path):
    if not os.path.isdir(dir_path):
        print(f"âš ï¸ {dir_path} ä¸å­˜åœ¨ï¼Œè·³è¿‡")
        return

    date = get_yesterday()
    archive_name = f"{os.path.basename(dir_path)}-backup-{date['year']}-{date['month']}-{date['day']}.tar.gz"
    archive_path = os.path.join(TMP_BASE, archive_name)

    print(f"\nğŸ“¦ æ‰“åŒ… {dir_path} â†’ {archive_path}")
    with tarfile.open(archive_path, "w:gz") as tar:
        tar.add(dir_path, arcname=os.path.basename(dir_path))

    s3_key = f"{S3_PREFIX}/{os.path.basename(dir_path)}/{date['year']}/{date['month']}/{date['day']}/{archive_name}"
    upload_file(archive_path, s3_key)
    clean_up(archive_path)

# ========== æ‰§è¡Œ ==========
if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹ Wazuh å‰ä¸€å¤©å¢é‡æ—¥å¿— + etc/ruleset/api å¤‡ä»½")
    backup_logs()

    for d in PACKAGE_DIRS:
        backup_dir(d)

    print("ğŸ‰ å¤‡ä»½å®Œæˆ")
